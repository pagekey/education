{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with PyTorch\n",
    "\n",
    "PyTorch is a widely-used Python library for deep learning. In this notebook, we'll cover the essentials of getting started with PyTorch:\n",
    "\n",
    "1. [Installing PyTorch](#part-1-installation)\n",
    "\n",
    "2. [Basic Data Structures](#part-2-basic-structures)\n",
    "\n",
    "3. [Training a Model](#part-3-training-a-model)\n",
    "\n",
    "4. [Performing inference with the model](#part-4-performing-inference)\n",
    "\n",
    "5. [Saving and Loading Models](#part-5-saving-and-loading-models)\n",
    "\n",
    "\n",
    "In this notebook, we'll install PyTorch, explore basic data structures, and train our first model. We'll show how you can use the model to make inferences on new data. Finally, we'll show how trained models can be saved and loaded to files.\n",
    "\n",
    "By the end, you'll have a solid foundation in PyTorch and be ready to apply it to your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Installation\n",
    "\n",
    "Ensure you have a virtual environment active. Then, run the following cell to install `torch` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install pip requirements.\n",
    "!pip install torch matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Structures\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "1. Import required packages.\n",
    "1. Create some tensors.\n",
    "1. Perform basic tensor operations.\n",
    "1. Demo Automatic Differentiation.\n",
    "1. Discuss moving to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D tensor (vector)\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(tensor)\n",
    "\n",
    "# Create a 2D tensor (matrix)\n",
    "tensor_2d = torch.tensor([[1, 2], [3, 4]])\n",
    "print(tensor_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise addition\n",
    "tensor_add = tensor + 2\n",
    "print(tensor_add)\n",
    "\n",
    "# Element-wise multiplication\n",
    "tensor_mul = tensor * 2\n",
    "print(tensor_mul)\n",
    "\n",
    "# Matrix multiplication\n",
    "matrix_mul = torch.matmul(tensor_2d, tensor_2d)\n",
    "print(matrix_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation\n",
    "\n",
    "Tensorflow has a built-in way to compute the differential of a given point. For example, given this equation:\n",
    "\n",
    "$$\n",
    "y = x^2 + 3x + 1\n",
    "$$\n",
    "\n",
    "We know from calculus class that the derivative is:\n",
    "\n",
    "$$\n",
    "y' = 2x + 3\n",
    "$$\n",
    "\n",
    "Tensorflow can figure this out for a specific point. Take $7$ as an example.\n",
    "\n",
    "- Original function: $2^2 + 3*2 + 1 = 4 + 6 + 1 = 11$\n",
    "- Derivative: $2*2 + 3 = 7$\n",
    "\n",
    "Using `requires_grad=True`, we can run `y.backward()` and check to see if the gradient matches our calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with requires_grad=True to track operations on it.\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Use the tensor for computation.\n",
    "y = x**2 + 3*x + 1\n",
    "\n",
    "print(f\"Original function: {y}\")\n",
    "\n",
    "# Compute gradients. This sets the `x.grad` field but does not change `y`.\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient (dy/dx)\n",
    "print(f\"Gradient: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Tensors to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor_gpu = tensor.to('cuda')\n",
    "    print(tensor_gpu)\n",
    "else:\n",
    "    print(\"GPU not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training a Model\n",
    "\n",
    "Overview of steps:\n",
    "\n",
    "1. Create example dataset.\n",
    "1. Define a linear model: $y=Wx+b$.\n",
    "   - $W$ is the weight.\n",
    "   - $b$ is the bias.\n",
    "1. Train the model using training data. The model adjusts $W$ and $b$ to minimize the loss function.\n",
    "1. Perform inference with the trained model. Given an arbitrary input, use the model to predict the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some example data.\n",
    "# Data will match the following function outputs: y = 2 * x + 1.\n",
    "# In a real-world scenario, this data could come from measurements or other sources.\n",
    "X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
    "y = torch.tensor([[3.0], [5.0], [7.0], [9.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data.\n",
    "plt.scatter(X.numpy(), y.numpy(), label=\"Data point\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Training data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple linear model.\n",
    "# The model we're defining is a linear model, which means it tries to fit a straight line to the data.\n",
    "# `nn.Linear` creates a linear transformation, essentially computing y = Wx + b, where W is the weight and b is the bias.\n",
    "model = nn.Linear(in_features=1, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer\n",
    "# The loss function measures how well the model's predictions match the true outputs (y).\n",
    "# In this case, we use Mean Squared Error (MSE), which is a common loss function for regression problems.\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# The optimizer is responsible for updating the model's weights based on the gradients computed during backpropagation.\n",
    "# Here, we're using Stochastic Gradient Descent (SGD), a simple and widely used optimization algorithm.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we enter the training loop, where we repeatedly adjust the model's parameters to minimize the loss.\n",
    "epochs = 1000  # Number of times we will go through the entire dataset\n",
    "loss_values = []  # List to store loss values for plotting later\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: compute predicted y by passing X to the model.\n",
    "    # The \"forward pass\" refers to the process where the input data (X) is passed through the model to get the output (y_pred). \n",
    "    # It is called \"forward\" because it moves in the direction from inputs to outputs in the network.\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # Compute the loss.\n",
    "    # The loss function compares the model's predictions (y_pred) with the true outputs (y) and returns a value indicating how far off the predictions are.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    \n",
    "    # Save the loss so that we can plot it.\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    # Gradients are the derivatives of the loss function with respect to the model's parameters. They indicate how much each parameter should be adjusted to minimize the loss.\n",
    "    # A \"backward pass\" computes these gradients by propagating the error backward through the network. It involves calculating the gradient of the loss with respect to each parameter.\n",
    "    \n",
    "    # `optimizer.zero_grad()` clears old gradients from the previous step (otherwise they would accumulate).\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # `loss.backward()` computes the gradient of the loss with respect to the model's parameters (weights and bias).\n",
    "    # This is the \"backward pass\" and is part of the backpropagation algorithm.\n",
    "    loss.backward()\n",
    "\n",
    "    # `optimizer.step()` updates the model's parameters using the gradients computed in the backward pass.\n",
    "    # This is where the actual learning happens, as the model adjusts its weights to reduce the loss.\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs.\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Performing Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference for a single point.\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calcualtion for inference.\n",
    "    new_X = torch.tensor([[5.0]])  # Example input\n",
    "    predicted_y = model(new_X)\n",
    "    print(f\"Predicted y for input 5.0: {predicted_y.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference for the entire original X domain.\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results against original training data.\n",
    "plt.scatter(X.numpy(), y.numpy(), label=\"Training\")\n",
    "plt.scatter(X.numpy(), y_pred.numpy(), label=\"Predicted\", color=\"red\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Training vs inference\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over epochs.\n",
    "plt.plot(range(epochs), loss_values, label=\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(loss_values[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Saving and Loading Models\n",
    "\n",
    "You have two options:\n",
    "\n",
    "- Save Model State *Only* (Weights and Biases):\n",
    "  - This is generally the preferred approach.\n",
    "  - Flexible and portable. Common when collaborating or using a model in production.\n",
    "  - Must redefine model architecture to load.\n",
    "- Save the entire model (including architecture).\n",
    "  - Easier to use - no need to define architecture to load.\n",
    "  - Avoids human error (redefining complex architectures).\n",
    "  - More convenient for experimenting / prototyping phases.\n",
    "\n",
    "In our case, \"redefining the architecture\" would be as simple as instantiating the Linear model again. For more complex models, this would require re-defining all layers and configuration.\n",
    "\n",
    "As a reminder, our model is: $y=2x+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Saving the Model State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state to a file\n",
    "torch.save(model.state_dict(), 'model_state.pth')\n",
    "\n",
    "# Redefine the architecture (instantiate the model)\n",
    "model_loaded = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "# Show that inference is wrong before loading states.\n",
    "print(\"Before load: \", model_loaded(X))\n",
    "\n",
    "# Load the saved state dict into the newly instantiated model\n",
    "model_loaded.load_state_dict(torch.load('model_state.pth', weights_only=True))\n",
    "\n",
    "# Set the model to evaluation mode (important for inference)\n",
    "model_loaded.eval()\n",
    "\n",
    "# Infer again now that weights/biases have been loaded.\n",
    "print(\"After load: \", model_loaded(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Saving / Loading Entire Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a file.\n",
    "torch.save(model, 'model_complete.pth')\n",
    "\n",
    "# Load the entire model\n",
    "entire_model_loaded = torch.load('model_complete.pth', weights_only=False)\n",
    "\n",
    "# Set the model to evaluation mode (important for inference)\n",
    "entire_model_loaded.eval()\n",
    "\n",
    "# Perform inference again.\n",
    "print(\"After loading entire model: \", entire_model_loaded(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Thanks for checking out this notebook! I hope it helped you learn something new."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
